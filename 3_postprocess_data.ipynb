{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "28ed63eb-4e64-4608-9169-583c604f354f",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import os\n",
    "import math\n",
    "import numpy as np\t"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 143,
   "id": "53e926a7-89ad-485e-9c0e-02000af86959",
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_highly_correlated_features(X_train, threshold=0.7):\n",
    "    \"\"\"\n",
    "    Remove highly correlated features from the training dataset.\n",
    "    \"\"\"\n",
    "\n",
    "    # Dictionary to hold features categorized by their base name\n",
    "    dist_dict = {}\n",
    "    for feature in X_train.columns:\n",
    "        dist_name, _ = feature.split(\"_\")\n",
    "        if dist_name not in dist_dict:\n",
    "            dist_dict[dist_name] = [feature]\n",
    "        else:\n",
    "            dist_dict[dist_name].append(feature)\n",
    "    \n",
    "    keep_features = []\n",
    "    \n",
    "    # Iterate over each group of features with the same base name\n",
    "    for key, features in dist_dict.items():\n",
    "        data_subset = X_train[features]\n",
    "        \n",
    "        corr_matrix = data_subset.corr().abs()\n",
    "        upper_triangle = corr_matrix.where(np.triu(np.ones(corr_matrix.shape), k=1).astype(bool))\n",
    "        to_drop = [column for column in upper_triangle.columns if any(upper_triangle[column] > threshold)]\n",
    "        data_subset.drop(labels=to_drop, axis=1, inplace=True)\n",
    "        keep_features.extend(data_subset.columns)\n",
    "        \n",
    "        print(f\"Category '{key}':\")\n",
    "        print(f\"  Number of features before removal: {len(features)}\")\n",
    "        print(f\"  Number of features after removal: {data_subset.shape[1]}\")\n",
    "    \n",
    "    print(f\"\\nTotal number of features before removal: {X_train.shape[1]}\")\n",
    "    print(f\"Total number of features after removal: {len(keep_features)}\")\n",
    "    \n",
    "    return keep_features"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "79f8161f-bb8e-4abc-ab40-99d32a3c38b5",
   "metadata": {},
   "source": [
    " - Step 1: Convert shapelets to features\n",
    "     - Transform mined shapelets into feature vectors by measuring distances to the original time series.\n",
    " - Step 2: Remove redundancy\n",
    "     - Ensure extracted patterns are informative, relevant, and not excessively similar.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "2a918455-710a-4cdd-98ff-fc3ce6599949",
   "metadata": {},
   "outputs": [],
   "source": [
    "path_res = 'csv_results'\n",
    "listdir = os.listdir(path_res)\n",
    "\n",
    "Train = pd.DataFrame()\n",
    "Test = pd.DataFrame()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "61cb6924-9c55-4fe5-8e4e-269bee5d5cc5",
   "metadata": {},
   "source": [
    "## step 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "814be820-4fd6-436a-9228-a66327e97f2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for dist_file in listdir:\n",
    "    if \"Train\" in dist_file:\n",
    "        train_dist_path = os.path.join(path_res, dist_file)\n",
    "        dist_name = dist_file.split('_')[1]\n",
    "        test_dist_path = os.path.join(path_res, f\"Test_{dist_name}_2_4_metrics.csv\")\n",
    "        \n",
    "        try:\n",
    "            df_train = pd.read_csv(train_dist_path)\n",
    "            df_test = pd.read_csv(test_dist_path)\n",
    "            \n",
    "            df_train = df_train.sort_values('p_val')\n",
    "            df_test = df_test.reindex(df_train.index)\n",
    "            \n",
    "            df_train = df_train.reset_index(drop=True)\n",
    "            df_test = df_test.reset_index(drop=True)\n",
    "\n",
    "            for df, save_df in zip([df_train, df_test], [Train, Test]):\n",
    "                shapelet_num = min(len(df['distances']), 100)  # Limit the number of shapelets to 100\n",
    "                \n",
    "                for i in range(shapelet_num):\n",
    "                    # Extract shapelet information\n",
    "                    nums = df[\"shapelet\"][i][1:-1].split(', ')\n",
    "                    nums = [int(num) for num in nums]  # Convert to integer list\n",
    "                    string = ''.join(map(str, nums))  # Convert list back to string\n",
    "                    \n",
    "                    # Process distances\n",
    "                    list_ = df['distances'][i][1:-1].split(',')\n",
    "                    dist = [np.nan if math.isnan(float(a)) else int(float(a)) for a in list_]\n",
    "                    \n",
    "                    # Add processed distances to the DataFrame\n",
    "                    save_df[f'{dist_name}_{str(string)}'] = dist\n",
    "        except Exception as e:\n",
    "            print(f\"Error processing {train_dist_path}: {e}\")\n",
    "\n",
    "\n",
    "# Train['label'] = (pd.read_csv(\"data/synthetic/y_train.csv\")[\"label\"]).astype(int)\n",
    "# Test['label'] = (pd.read_csv(\"data/synthetic/y_test.csv\")[\"label\"]).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "8c3228ca-c023-4715-95d6-453979c5cb19",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>threshold</th>\n",
       "      <th>acc</th>\n",
       "      <th>p_val</th>\n",
       "      <th>contingency</th>\n",
       "      <th>shapelet</th>\n",
       "      <th>distances</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>[17, 25, 3, 39]</td>\n",
       "      <td>[2, 3]</td>\n",
       "      <td>[nan, 0.0, nan, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>0.675</td>\n",
       "      <td>0.000335</td>\n",
       "      <td>[17, 25, 3, 39]</td>\n",
       "      <td>[1, 3]</td>\n",
       "      <td>[nan, 1.0, nan, 2.0, 5.0, 2.0, 4.0, 2.0, 2.0, ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   threshold    acc     p_val      contingency shapelet  \\\n",
       "0          0  0.675  0.000335  [17, 25, 3, 39]   [2, 3]   \n",
       "1          1  0.675  0.000335  [17, 25, 3, 39]   [1, 3]   \n",
       "\n",
       "                                           distances  \n",
       "0  [nan, 0.0, nan, 1.0, 2.0, 1.0, 1.0, 1.0, 1.0, ...  \n",
       "1  [nan, 1.0, nan, 2.0, 5.0, 2.0, 4.0, 2.0, 2.0, ...  "
      ]
     },
     "execution_count": 141,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_test.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 142,
   "id": "8280ae53-f91a-4728-88cd-58977fd1cb96",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1_23</th>\n",
       "      <th>feature1_13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1.0</td>\n",
       "      <td>2.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature1_23  feature1_13\n",
       "0           NaN          NaN\n",
       "1           0.0          1.0\n",
       "78          0.0          1.0\n",
       "79          1.0          2.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.concat([Test.head(2), Test.tail(2)]))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118e42ba-3aa0-4c3c-b5dd-08a0d495b8b7",
   "metadata": {},
   "source": [
    "## step 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 146,
   "id": "97e4e23e-076f-4e01-805a-2df7ddaf834f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Category 'feature1':\n",
      "  Number of features before removal: 2\n",
      "  Number of features after removal: 1\n",
      "\n",
      "Total number of features before removal: 2\n",
      "Total number of features after removal: 1\n"
     ]
    }
   ],
   "source": [
    "keep_feat = remove_highly_correlated_features(Train, 0.6)\n",
    "X_train = Train[keep_feat]\n",
    "X_test = Test[keep_feat]\n",
    "\n",
    "X_test = X_test[X_train.columns]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 147,
   "id": "85a903c0-02b5-4f22-a30b-4ceef72a5a89",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>feature1_23</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78</th>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>79</th>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    feature1_23\n",
       "0           NaN\n",
       "1           0.0\n",
       "78          0.0\n",
       "79          1.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(pd.concat([X_test.head(2), X_test.tail(2)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 148,
   "id": "55db1bd3-f5df-427e-9736-2396123d507d",
   "metadata": {},
   "outputs": [],
   "source": [
    "save_path = os.path.join('data', 'synthetic')\n",
    "os.makedirs(save_path, exist_ok=True)\n",
    "\n",
    "# If you have other patient details like age and gender, \n",
    "# add them to the data. Make sure they match the order of the patient records in X_train and X_test\n",
    "\n",
    "# X_train_updated = pd.concat([X_train, static_features_train], axis=1)\n",
    "# X_test_updated = pd.concat([X_test, static_features_test], axis=1)\n",
    "\n",
    "# X_train_updated.to_csv(os.path.join(save_path, 'X_train.csv'), index=False)\n",
    "# X_test_updated.to_csv(os.path.join(save_path, 'X_test.csv'), index=False)\n",
    "\n",
    "X_train.to_csv(os.path.join(save_path, 'X_train.csv'), index=False)\n",
    "X_test.to_csv(os.path.join(save_path, 'X_test.csv'), index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6a3fff8-f98c-4a88-8c46-93eff40a82a5",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
